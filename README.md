# ğŸ§  RAG-Based Legal Chatbot

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-brightgreen)
![React](https://img.shields.io/badge/React-Frontend-blue)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

An intelligent legal assistant that answers questions based on uploaded legal contracts using Retrieval-Augmented Generation (RAG), FAISS similarity search, and a locally hosted Mistral LLM.

---

## ğŸ“ Project Structure

```
RAG-LEGAL-CHATBOT/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                  # FastAPI backend with chat + upload endpoints
â”‚   â”œâ”€â”€ rag_mistral_chatbot.py  # RAG logic (retrieval + generation)
â”‚   â”œâ”€â”€ extract_text.py         # AWS Textract/local text extraction
â”‚   â”œâ”€â”€ generate_embedding.py   # FAISS index builder
â”‚   â”œâ”€â”€ requirements.txt        # Python dependencies
â”‚   â”œâ”€â”€ embeddings/             # FAISS index + file list
â”‚   â”œâ”€â”€ extracted_text/         # Extracted legal texts (txt)
â”‚   â””â”€â”€ models/                 # LLM .gguf model file
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx             # Main React UI
â”‚   â”‚   â””â”€â”€ App.css             # Styling
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js

---

## âœ¨ Features

- ğŸ“„ Upload `.txt` legal contracts
- ğŸ” Generate embeddings and index them in FAISS
- ğŸ¤– Ask legal questions based on uploaded docs
- ğŸ§  Uses a local Mistral 7B GGUF model (via llama-cpp-python)
- ğŸ’¬ Responsive real-time chat interface
- ğŸŒ FastAPI backend with React frontend

---

## ğŸ–¥ï¸ Chatbot Preview

<img width="959" alt="Image" src="https://github.com/user-attachments/assets/3bb20335-ecd8-4813-bd09-85412788dc55" />

---

## ğŸ› ï¸ Getting Started

### ğŸ§ª Backend (FastAPI + Mistral)

```bash
# Install Python packages
pip install -r requirements.txt

# Run backend
uvicorn main:app --reload
```

> â›°ï¸ Make sure your GGUF model is present inside `models/` and path is correct in `main.py`

---

### ğŸ’» Frontend (React + Vite)

```bash
cd frontend
npm install
npm run dev
```

Then visit: `http://localhost:5173`

---

## ğŸ¤– Model Used

- **Name:** Mistral 7B Instruct  
- **Format:** GGUF (`.gguf`)  
- **Quantization:** `Q4_K_M`  
- **Loaded with:** llama-cpp-python  

---

## ğŸ“¦ Uploading a File

- Click **Choose File** and upload `.txt` file
- File is saved and embedded on the backend
- You can now ask legal questions based on that content

---

## ğŸ§  Sample Q&A

```
Question: Can the contract be terminated early?

Answer: If the provider fails to meet their obligations under the agreement, the recipient may terminate the service...
```

---

## ğŸš Deployment

### Option A: Local  
Run both frontend and backend locally (default).

### Option B: Render + Netlify  
- Backend: Upload to [Render](https://render.com/)
- Frontend: Deploy using [Netlify](https://netlify.com/)  
(Ensure proper `CORS` handling and public APIs)

---

## ğŸ“œ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ˜‹ Author

**Akshita Aluru**  
ğŸ“§ aakshitareddy@gmail.com  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/akshita-aluru-7664a1217)

